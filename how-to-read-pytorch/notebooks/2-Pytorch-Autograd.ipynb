{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic 2: Pytorch Autograd\n",
    "================\n",
    "\n",
    "If you flag a torch Tensor with the attribute `x.requires_grad=True`, then pytorch will automatically keep track the computational history of all tensors that are derived from `x`.  This allows pytorch to figure out derivatives of any scalar result with regard to changes in the components of x.\n",
    "\n",
    "The function `torch.autograd.grad(output_scalar, [list of input_tensors])` computes `d(output_scalar)/d(input_tensor)` for each input tensor component in the list.  For it to work, the input tensors and output must be part of the same `requires_grad=True` compuation.\n",
    "\n",
    "In the example above, `x` is explicitly marked `requires_grad=True`, so `y.sum()`, which is derived from `x`, automatically comes along with the computation history, and can be differentiated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "x = torch.linspace(0, 5, 100, requires_grad=True)\n",
    "y = (x**2).cos()\n",
    "dydx = torch.autograd.grad(y.sum(), [x])[0]\n",
    "\n",
    "plt.plot(x.detach(), y.detach(), label='y')\n",
    "plt.plot(x.detach(), dydx, label='dy/dx')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note that in the example above, because the components of the vector space are independent of each other, we happen to have `d(y.sum())/dx[i] = dy[i]/dx[i]`, so computing a single gradient vector of the sum is equiavlent to computing elementwise derivatives.)\n",
    "\n",
    "**Detaching tensors from the computation history.** Every tensor that depends on `x` will be `requires_grad=True` and connected to the complete computation history. But if you were to convert a tensor to a regular python number, pytorch would not be able to see the calculations and would not be able to compute gradients on it. To avoid programming mistakes where some computation invisibly goes through a non-pytorch number that cannot be tracked, pytorch disables requires-grad tensors from being converted to untrackable numbers.  You need to explicitly call `x.detach()` or `y.detach()` first, to explicitly say that you want an untracked reference, before plotting the data or using it as non-pytorch numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Plot the polynomial y=x<sup>3</sup>-6x<sup>2</sup>+8x and its derivative, instead of cos(x<sup>2</sup>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backprop and In-place gradients\n",
    "-------------------------------\n",
    "\n",
    "In a typical neural network we will not just be getting gradients with regard to one input like `x` above, but with regard to a list of dozens or hundreds of tensor parameters that have all been marked with `requires_grad=True`.  It can be inconvenient to keep track of which gradient outputs go with which original tensor input.  But since the gradients have exactly the same shape as the inputs, it is natural to store computed gradients in-place on the tensors themselves.\n",
    "\n",
    "**Using `backward()` to add `.grad` attributes.** To simplify this common operation, pytorch provides the `y.backward()` method, which computes the gradients of y with respect to every tracked dependency, and stores the results in the field `x.grad` for every original input vector `x` that was marked as `requires_grad=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(0, 5, 100, requires_grad=True)\n",
    "y = (x**2).cos()\n",
    "y.sum().backward()   # populates the grad attribute below.\n",
    "print(x.grad)\n",
    "\n",
    "plt.plot(x.detach(), y.detach(), label='y')\n",
    "plt.plot(x.detach(), x.grad, label='dy/dx')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "1. Introduce a new vector x<sub>2</sub> which also ranges from zero to five (same as x, but not cloned from x).\n",
    "2. Plot the polynomial y=x<sub>2</sub><sup>3</sup>-6x<sup>2</sup>+8x\n",
    "3. Plot dy/dx and dy/dx<sub>2</sub>.\n",
    "\n",
    "Which x contributes most to the gradient at zero?  At five?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accumulating and Zeroing grad\n",
    "-----------------------------\n",
    "\n",
    "**Gradient accumulation.** If you find that your data batches are too large to get gradients of the\n",
    "whole thing, then it is usually possible to split the batches into smaller pieces and add the\n",
    "gradients. Because gradient accumulation is a common pattern, if you call `.backward()` when parameters\n",
    "`x.grad` already exists, it is not an error.  The new gradient will be *added* to the old one.\n",
    "\n",
    "**zero_grad().** That means that you need to set any previous value of `x.grad` to zero before\n",
    "running `backward()`, or else the new gradient will be added to the old one.  Optimizers have a\n",
    "utility `optim.zero_grad()` to do this to all the optimized parameters at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving memory on inference\n",
    "--------------------------\n",
    "\n",
    "**Avoid autograd when you don't need it.** Normally, all the parameters of a neural network are set to `requires_grad=True` by default, so they are ready to be trained.  But that means that whenever you run a network, you will get output which is also requires-grad, and it will be attached to a long computation history that consumes a lot of precious GPU memory.\n",
    "\n",
    "To avoid all this expense when you have no intention of training the network, you could go through all the network parameters to set `requires_grad=False`.\n",
    "\n",
    "Another way to avoid the computation history is to enclose the entire computation within a `with torch.no_grad():` block.  This will suppress all the autograd mechanics (which means, of course, `.backward()` will not function).\n",
    "\n",
    "Note that this is different from the role of `net.eval()` which puts puts the network in inference mode computationally (batchnorm, dropout, and other operations behave differently in training and inference); `net.eval()` does not have any effect on `requires_grad`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More tricks\n",
    "-----------\n",
    "\n",
    "**Gradients over intermediate values.** Normally gradients with respect to intermediate values are not stored in `.grad` - just original input variables - but you can ask for intermediate gradients to be stored using `v.retain_grad()`.\n",
    "\n",
    "**Second derivatives.** If you want higher-order derivatives, then you want pytorch to build the computation graph when it is computing the gradient itself, so this graph can be differentiated again.  To do this, use the `create_graph=True` option on the `grad` or `backward` methods.\n",
    "\n",
    "**Gradients of more than one objective.** Usually you only need to call `y.backward()` once per computation tree, and pytorch will not let you call it again. To save memory, pytorch will have deallocated the computation graph after you have computed a single gradient.  But if you need more than one gradient (e.g., if you have different objectives that you want to apply to different subsets of parameters, as with happens with GANs sometimes), you can use `retain_graph=True`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "1. Plot the polynomial y=x<sup>3</sup>-6x<sup>2</sup>+8x, just as in the first exercise.\n",
    "2. Use `y.sum().backward(create_graph=True)` to compute the gradient, and plot dy/dx.  Why is `x.grad.detach()` needed now?\n",
    "3. Now set `dy = x.grad.clone()` and then `x.grad.zero_()`, before using `dy.sum().backward()` to compute a 2nd gradient.  Plot d<sup>2</sup>y/dx."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [On to topic 3: Optimizers &rightarrow;](3-Pytorch-Optimizers.ipynb)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}